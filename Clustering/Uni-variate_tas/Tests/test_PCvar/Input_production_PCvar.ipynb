{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce input for clustering analysis \n",
    "Step of the codes :\n",
    "- Import [modules](#modules) \n",
    "- Define [settings](#settings) \n",
    "- Define [functions](#functions) \n",
    "- [Download Mean and weights](#down_mean) used for EOF analysis \n",
    "- [Dowload reference data](#down_p1) \n",
    "- [Downoad EOF solver](#down_EOF) \n",
    "- Get the [PPE PC](#PPE_pc) \n",
    "- [Download observations](#down_obs) (compute anomalies and weight)\n",
    "- [Project observations](#proj_obs) to get pseudo-PC \n",
    "- [Predict new LHS pseudo-PC](#predict)\n",
    "- Produce xarray\n",
    "- [Save](#save) the xarray as netCDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id = 'modules'>Import Module<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/scratch/globc/peatier/conda/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Computational modules \n",
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "from array import array\n",
    "from pylab import *\n",
    "#import geopandas\n",
    "from eofs.xarray import Eof\n",
    "from eofs.multivariate.standard import MultivariateEof\n",
    "import random\n",
    "\n",
    "# Plotting modules \n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "import pandas.plotting\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from cartopy.util import add_cyclic_point\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import dual_annealing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='settings'>Settings<a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['tas', 'pr', 'psl', 'SW', 'LW']\n",
    "var_ceres = ['rsdt','rsut', 'rlut']\n",
    "truncations = [18, 18, 8, 28, 22]\n",
    "TITLE = 'Multi-variate'\n",
    "ylabel = '$E_{tot}$'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_official='/data/scratch/globc/peatier/CMIP6/CNRM-CM6-1/CFMIP/amip/'\n",
    "path_PPE='/data/scratch/globc/peatier/PPE/CNRM-CM6-1_PPE/'\n",
    "path_files='/data/home/globc/peatier/PPE/CNRMppe_error_decomposition/files/'\n",
    "path_file_npy = '/data/home/globc/peatier/PPE/CNRMppe_save/PPE/ENSEMBLE2/files/npy/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_p_list = ['p311', 'p312', 'p314', 'p316',\n",
    "                    'p317', 'p319', 'p320', 'p321', 'p322', 'p324', 'p325', 'p326', \n",
    "                    'p329', 'p330', 'p331', 'p332', 'p335', 'p336', 'p337' ,'p338', \n",
    "                    'p340', 'p341', 'p343', 'p344', 'p346', 'p347', 'p348', 'p349', \n",
    "                    'p350', 'p353', 'p355', 'p357', 'p359', 'p360', \n",
    "                    'p361', 'p363', 'p365', 'p367', 'p368', 'p369', \n",
    "                    'p372', 'p373', 'p374', 'p375', 'p376', 'p378', 'p381', 'p382', \n",
    "                    'p384', 'p386', 'p388', 'p389', 'p391', 'p392', 'p393', \n",
    "                    'p394', 'p395', 'p396', 'p398', 'p399', 'p400', 'p404', \n",
    "                    'p406', 'p407', 'p409', 'p410', 'p411', 'p412',\n",
    "                    'p414','p416',\n",
    "                    'p413','p419','p424','p426','p428','p421','p423',\n",
    "                    'p425','p427','p429','p430','p436','p438','p431','p433',\n",
    "                    'p442','p446','p443','p445','p447',\n",
    "                    'p452','p454','p456','p458','p457','p459',\n",
    "                    'p460','p465','p467','p469',\n",
    "                    'p470','p471']\n",
    "\n",
    "len(nb_p_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='functions'>Functions<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3D_tas_xarr(path, filename, variables):\n",
    "#    “”\"\n",
    "#    This function read the netCDF file of monthly data, compute the radiative budget, perform a yearly mean and \n",
    "#    return a dataframe\n",
    "#    “”\"\n",
    "    # First step : download the data into dataframe\n",
    "    file = xr.open_mfdataset(path+filename,combine='by_coords')\n",
    "    #\n",
    "    # Second step : compute the annual average \n",
    "    df = file[variables].mean('time', keep_attrs=True)\n",
    "    tas = df['tas']\n",
    "    #\n",
    "    return tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_monthly_clim(path, filename, variables) :\n",
    "    \n",
    "    file = xr.open_mfdataset(path+filename,combine='by_coords')\n",
    "    df=file[variables].to_dataframe()\n",
    "    \n",
    "    # Compute Climatological Annual Cycle :\n",
    "    df1=df.reset_index(level=['time', 'lat', 'lon'])\n",
    "    df1['year']=pd.DatetimeIndex(df1['time']).year\n",
    "    df1['month']=pd.DatetimeIndex(df1['time']).month\n",
    "    \n",
    "    #list_ind = []\n",
    "    #cpt=0\n",
    "    #for i in df1['year'] : \n",
    "    #    if i>1981 :\n",
    "    #        list_ind.append(cpt)\n",
    "    #        cpt+=1\n",
    "    #    else : \n",
    "    #        cpt+=1\n",
    "            \n",
    "    #df2 = df1.drop(list_ind)\n",
    "    df_mean=df1.groupby(['month', 'lat', 'lon']).mean()\n",
    "    df_mean=df_mean.drop(columns='year')\n",
    "    \n",
    "    return df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiLinReg_pred(LHS, X ,y, param_names) :\n",
    "\n",
    "    LHS_df = pd.DataFrame(LHS)\n",
    "\n",
    "    lhs = LHS_df.values\n",
    "    #LHS_df\n",
    "\n",
    "    # Let's use the model equation : \n",
    "\n",
    "    X_df = pd.DataFrame(data=X)\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(X, y)\n",
    "    R = regr.intercept_\n",
    "    Coeffs = pd.DataFrame([regr.coef_]*30, columns=param_names).iloc[0]\n",
    "\n",
    "    N=len(LHS_df.values)\n",
    "    tmp = [0]*N\n",
    "    y_pred = [0]*N\n",
    "    i=0\n",
    "    Ycpt=0\n",
    "    while i<N:\n",
    "        \n",
    "        tmp[i] = Coeffs.values*LHS_df.iloc[i]\n",
    "        y_pred[i] = tmp[i].sum()+R\n",
    "        i+=1\n",
    "\n",
    "    #y_pred\n",
    "    #members = arange(102,100102,1)\n",
    "    #DFYpred = pd.DataFrame([y_pred, members], index=[\"y_pred\", \"members\"]).transpose()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id = 'down_mean'>General data<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = path_files+'npy/'\n",
    "Mean={}\n",
    "for var in variables :\n",
    "    filename = 'CNRMppe_decomposition_mean_'+str(var)+'.npy'\n",
    "    Mean_tmp =  pd.read_pickle(path_file+filename).to_xarray().to_array()\n",
    "    Mean[str(var)] = Mean_tmp[0,:,:].rename({'variable':'mode'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in variables :\n",
    "    W_eof_2D = np.load(path_files+'npy/W_eof_2D_'+str(var)+'.npy')\n",
    "    W_eof_3D = np.load(path_files+'npy/W_eof_3D_'+str(var)+'.npy')\n",
    "    W_rmse_2D = np.load(path_files+'npy/W_rmse_2D_'+str(var)+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='down_p1'>Reference p1<a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference simulation\n",
    "path = path_PPE+'ENSEMBLE1/CNRM-CM6-1_amip_PPE/CNRM-CM6-1_amip_r1i1p1f2/'\n",
    "filename = 'tas_*_CNRM-CM6-1_amip_*.nc'\n",
    "p1_amip = get_3D_tas_xarr(path, filename, ['tas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --Anom and weight\n",
    "X_p1 = p1_amip - Mean['tas']\n",
    "X_p1_w = X_p1*W_eof_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id ='PPE_pc'>Download EOF solvers and get PPE pc and p1 pc<a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path = path_files+'pkl/'\n",
    "solver = {}\n",
    "for var in variables :\n",
    "    #print(var)\n",
    "\n",
    "    # open a file, where you stored the pickled data\n",
    "    file = open(path+'solver_'+var+'.pkl', 'rb')\n",
    "\n",
    "    # dump information to that file\n",
    "    solver[var] = pickle.load(file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eofs = {}\n",
    "variances = {}\n",
    "for var in variables :\n",
    "    eofs[var] = solver[var].eofsAsCovariance(pcscaling=0)\n",
    "    variances[var] = solver[var].varianceFraction() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt = 0\n",
    "for var in variables :\n",
    "    #print(var)\n",
    "    trunc = truncations[cpt]\n",
    "    #print(trunc)\n",
    "    v = variances[var][0:trunc].sum()\n",
    "    #print(float(v))\n",
    "    cpt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = X_p1_w['lat']\n",
    "lon = X_p1_w['lon']\n",
    "eofs_nb = arange(1,104,1)\n",
    "eofs_xr = {}\n",
    "eofs_combined = {}\n",
    "\n",
    "for var in variables :\n",
    "    eofs_xr[var] = xr.DataArray(eofs[var], \n",
    "                   coords={'eofs': eofs_nb,'lat': lat,'lon': lon}, \n",
    "                   dims=[\"eofs\", \"lat\", \"lon\"])#.to_dataset(name=var)\n",
    "    ## --Combine the modes for reconstruction\n",
    "    eofs_combined[var] = eofs_xr[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PPE simulations \n",
    "var_modes = {}\n",
    "pc_PPE = {}\n",
    "for var in variables :\n",
    "    #print(var)\n",
    "    var_modes[var] = solver[var].varianceFraction()\n",
    "    pc_PPE[var] = solver[var].pcs(pcscaling=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For the reference p1 \n",
    "pc_p1 = {}\n",
    "for var in variables :\n",
    "    pc_p1[var] = pc_PPE[var][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id = 'down_obs'>Dowload observations<a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST observations - tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_observation = '/data/scratch/globc/peatier/obs/BEST/'\n",
    "filename = 'Land_and_Ocean_LatLong1_regrid_1979-1981.nc'\n",
    "var = 'tas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POUR LES OBSERVATIONS BEST\n",
    "\n",
    "path = path_observation\n",
    "\n",
    "file =  xr.open_mfdataset(path+filename,combine='by_coords')\n",
    "clim = file['climatology'].to_dataframe()#.drop(columns='month_number')\n",
    "clim = pd.concat([clim, clim, clim]).reset_index('month_number')\n",
    "\n",
    "df_obs=file['temperature'].to_dataframe().reset_index('time')\n",
    "df_obs['temperature'] = df_obs['temperature']\n",
    "df_obs['clim'] = clim['climatology']\n",
    "df_obs['tas'] = df_obs['temperature']+df_obs['clim']+273.15\n",
    "variable_obs = 'ta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = {}\n",
    "obs[var] = df_obs[var].groupby(['lat','lon']).mean().to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPCP observations - pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_observation = '/data/scratch/globc/peatier/obs/GPCP/regrid_CNRM/'\n",
    "filename_obs = 'pr_mon_mean_197901-198112_regrid.nc'\n",
    "var = 'pr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Initial method\n",
    "path = path_observation\n",
    "df_obs = load_monthly_clim(path, filename_obs, var)\n",
    "obs[var] = df_obs[var].groupby(['lat','lon']).mean().to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CERES observations - fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_observation = '/data/scratch/globc/peatier/obs/CERES/'\n",
    "filename = 'CERES_EBAF-TOA_Ed4.1_Subset_200003-201910_regrid.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and compute Annual Cycle :\n",
    "file = xr.open_mfdataset(path_observation+filename,combine='by_coords')\n",
    "#file\n",
    "variables = ['toa_sw_all_mon','toa_lw_all_mon', 'toa_net_all_mon']\n",
    "df_obs = load_monthly_clim(path_observation, filename, variables)\n",
    "#df_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs['SW'] =   df_obs['toa_sw_all_mon']# + df_obs['toa_lw_all_mon']\n",
    "obs['SW'] = df_obs.groupby(['lat','lon']).mean().to_xarray()\n",
    "obs['SW'] = obs['SW']['SW']\n",
    "\n",
    "df_obs['LW'] =  df_obs['toa_lw_all_mon']\n",
    "obs['LW'] = df_obs.groupby(['lat','lon']).mean().to_xarray()\n",
    "obs['LW'] = obs['LW']['LW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCEP observations - psl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_observation =  '/data/scratch/globc/peatier/obs/NCEP/regrid_CNRM/'\n",
    "filename_obs = 'psl_1m_1979-1981_NCEP_regrid.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and compute Annual Cycle :\n",
    "file = xr.open_mfdataset(path_observation+filename_obs,combine='by_coords')\n",
    "#file\n",
    "var = ['psl']\n",
    "df_obs = load_monthly_clim(path_observation, filename_obs, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs['psl'] = df_obs.groupby(['lat','lon']).mean().to_xarray()\n",
    "obs['psl'] = obs['psl']['psl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['tas', 'pr', 'psl', 'SW', 'LW']\n",
    "X_obs = dict()\n",
    "X_obs_w = dict()\n",
    "for var in variables :\n",
    "\n",
    "    ## --Observations\n",
    "    X_obs[var] = obs[var] - Mean[var]\n",
    "    X_obs_w[var] = X_obs[var]*W_eof_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project observations - get pseudo-PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tas\n",
      "pr\n",
      "psl\n",
      "SW\n",
      "LW\n"
     ]
    }
   ],
   "source": [
    "variables = ['tas', 'pr', 'psl', 'SW', 'LW']\n",
    "## --Project and reconstruct the observations\n",
    "pc_obs = {}\n",
    "for var in variables :\n",
    "    print(var)\n",
    "    pc_obs[var] = solver[var].projectField(X_obs_w[var], neofs=trunc, weighted=False, eofscaling=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='predict'>Emulations 100 000<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['tas', 'pr', 'psl', 'SW', 'LW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tas\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "pr\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "psl\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "SW\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "LW\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "path = \"/data/home/globc/peatier/PPE/CNRMppe/PPE/ENSEMBLE2/files/npy\"\n",
    "LHS = np.load(file=path+\"/LHS100000_param_standard.npy\")\n",
    "X = np.load(file=path+\"/X_EmulateurFeedbacksN.npy\")\n",
    "param_names = np.load(file=path+\"/LHS_paramNames.npy\")\n",
    "\n",
    "\n",
    "pc_pred = {}\n",
    "\n",
    "for var in variables :\n",
    "    print(var)\n",
    "    \n",
    "    pc_pred_list = []\n",
    "    for i in range(0,25,1) :\n",
    "        print(i)\n",
    "        y = pc_PPE[var][1:, i]\n",
    "        tmp = MultiLinReg_pred(LHS, X ,y, param_names)\n",
    "        pc_pred_list.append(tmp)\n",
    "    \n",
    "    pc_pred[var] = pc_pred_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # <a id='save'>Save all the data<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tas\n",
      "pr\n",
      "psl\n",
      "SW\n",
      "LW\n"
     ]
    }
   ],
   "source": [
    "path_files = '/data/home/globc/peatier/PPE/CNRMppe_error_decomposition/files/'\n",
    "\n",
    "for var in variables :\n",
    "    print(var)\n",
    "    ## PPE\n",
    "    path = path_files+'nc/'\n",
    "    filename = 'pc_PPE_'+var+'_PCvariance.nc'\n",
    "    pc_PPE[var].to_netcdf(path+filename)\n",
    "    \n",
    "    ## observations\n",
    "    path = path_files+'nc/'\n",
    "    filename = 'pc_obs_'+var+'_PCvariance.nc'\n",
    "    pc_obs[var].to_netcdf(path+filename)\n",
    "    \n",
    "    ## p1 - the first line of pc_PPE\n",
    "    \n",
    "    ## predictions\n",
    "    path = path_files+'nc/'\n",
    "    filename = 'pc_pred_'+var+'_PCvariance.nc'\n",
    "    tmp = xr.DataArray(pc_pred[var], dims=[\"modes\", \"members\"])\n",
    "    tmp.to_netcdf(path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_PPE",
   "language": "python",
   "name": "basic_ppe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
